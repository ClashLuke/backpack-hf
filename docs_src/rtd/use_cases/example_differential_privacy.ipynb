{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Differentially Private SGD.\n=============================\n\n\nDifferentially Private Stochastic Gradient Descent (DP-SGD)\n`[Abadi et al., 2016] <https://arxiv.org/pdf/1607.00133.pdf#page=3>`_\nis a rather simple idea.\nInstead of doing a typical SGD update, with the sum of all gradients\nin a minibatch,\n\n\\begin{align}x' = x - \\gamma g,\n    \\quad\\quad\n    g = \\sum_i \\underbrace{g_i}_{\\text{individual gradients}},\\end{align}\n\nDP-SGD first truncates each individual gradient if their norm exceeds some threshold\n$C$ to ensure no single example influence the overall update too much,\n\n\\begin{align}\\tilde{g}_i = g_i / \\max(1, \\Vert g_i\\Vert_2/C),\n    \\quad\\quad\n    \\tilde{g} = \\sum_i \\tilde{g}_i,\\end{align}\n\nand adds Gaussian noise to the update,\n\n\\begin{align}x' = x - \\gamma (\\tilde{g} + \\epsilon),\n    \\quad\\quad\n    \\epsilon \\sim \\mathcal{N}(0, C \\sigma^2 I)\\end{align}\n\nThat's the TL:DR, anyway.\nIt is not too difficult to get to an implementation of DP-SGD that works,\nbut getting individual gradients from a minibatch in a way that scales can be\ntricky.\nThis examples shows how to use the :code:`BatchGrad` extension,\nwhich gives access to individual gradients.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Let's get the imports, configuration and some helper functions out of the way first.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "import torch\nfrom torch.optim import Optimizer\nimport torch.nn as nn\nfrom backpack import backpack, extend\nfrom backpack.extensions import BatchGrad, BatchL2Grad\nfrom backpack.utils.examples import get_mnist_dataloder\nimport matplotlib.pyplot as plt\n\nNUM_EPOCHS = 1\nPRINT_EVERY = 50\nMAX_ITER = 200\nBATCH_SIZE = 512\nDEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\ntorch.manual_seed(0)\n\n\ndef make_broadcastable(v, X):\n    \"\"\"Returns a view of `v` that can be broadcast with `X`.\n\n    If `v` is a one-dimensional tensor [N] and `X` is a tensor of shape\n    `[N, ..., ]`, returns a view of v with singleton dimensions appended.\n\n    Example:\n        `v` is a tensor of shape `[10]` and `X` is a tensor of shape `[10, 3, 3]`.\n        We want to multiply each `[3, 3]` element of `X` by the corresponding\n        element of `v` to get a matrix `Y` of shape `[10, 3, 3]` such that\n        `Y[i, a, b] = v[i] * X[i, a, b]`.\n\n        `w = make_broadcastable(v, X)` gives a `w` of shape `[10, 1, 1]`,\n        and we can now broadcast `Y = w * X`.\n    \"\"\"\n    broadcasting_shape = (-1, *[1 for _ in X.shape[1:]])\n    return v.reshape(broadcasting_shape)\n\n\ndef accuracy(output, targets):\n    predictions = output.argmax(dim=1, keepdim=True).view_as(targets)\n    return predictions.eq(targets).float().mean().item()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Creating the model and loading some data\n----------------------------------------\n\nWe will use a small CNN with 2 convolutions, 2 linear layers,\nand feed it some MNIST data.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "def make_small_cnn(outputs=10, channels=(16, 32), fc_dim=32, kernels=(8, 4)):\n    return nn.Sequential(\n        nn.ZeroPad2d((3, 4, 3, 4)),\n        nn.Conv2d(1, channels[0], kernels[0], stride=2, padding=0),\n        nn.ReLU(),\n        nn.MaxPool2d(2, stride=1),\n        nn.Conv2d(channels[0], channels[1], kernels[1], stride=2, padding=0),\n        nn.ReLU(),\n        nn.MaxPool2d(2, stride=1),\n        nn.Flatten(),\n        nn.Linear(channels[1] * 4 * 4, fc_dim),\n        nn.ReLU(),\n        nn.Linear(fc_dim, outputs),\n    )\n\n\nmnist_dataloader = get_mnist_dataloder()\n\nmodel = make_small_cnn().to(DEVICE)\nloss_function = nn.CrossEntropyLoss().to(DEVICE)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "and we need to ``extend`` the model so that ``BackPACK`` knows about it.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "model = extend(model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Computing clipped individual gradients\n-----------------------------------------------------------------\n\nBefore writing the optimizer class, let's see how we can use ``BackPACK``\non a single batch to compute the clipped gradients, without the overhead\nof the optimizer class.\n\nWe take a single batch from the data loader, compute the loss,\nand use the ``with(backpack(...))`` syntax to activate two extensions;\n``BatchGrad`` and ``BatchL2Grad``.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "x, y = next(iter(mnist_dataloader))\nx, y = x.to(DEVICE), y.to(DEVICE)\n\nloss = loss_function(model(x), y)\nwith backpack(BatchL2Grad(), BatchGrad()):\n    loss.backward()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "``BatchGrad`` computes individual gradients and ``BatchL2Grad`` their norm (squared),\nwhich get stored in the ``grad_batch`` and ``batch_l2`` attributes of the parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for p in model.parameters():\n    print(\n        \"{:28} {:32} {}\".format(\n            str(p.grad.shape), str(p.grad_batch.shape), str(p.batch_l2.shape)\n        )\n    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "To compute the clipped gradients, we need to know the norms of the complete\nindividual gradients, but ad the moment they are split across parameters,\nso let's reduce over the parameters\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "l2_norms_squared_all_params = torch.stack([p.batch_l2 for p in model.parameters()])\nl2_norms = torch.sqrt(torch.sum(l2_norms_squared_all_params, dim=0))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We can compute the clipping scaling factor for each gradient,\ngiven a maximum norm ``C``,\n\n\\begin{align}\\\\max(1, \\Vert g_i \\Vert/C),\\end{align}\n\nas a tensor of ``[N]`` elements.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "C = 0.1\nscaling_factors = torch.clamp_max(l2_norms / C, 1.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "All that remains is to multiply the individual gradients by those factors\nand sum them to get the update direction for that parameter.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "for p in model.parameters():\n    clipped_grads = p.grad_batch * make_broadcastable(scaling_factors, p.grad_batch)\n    clipped_grad = torch.sum(clipped_grads, dim=0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Writing the optimizer\n---------------------\nLet's do the same, but in an optimizer class.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "class DP_SGD(Optimizer):\n    \"\"\"Differentially Private SGD.\n\n    Arguments:\n        params (iterable): iterable of parameters to optimize or dicts defining\n            parameter groups\n        lr (float, optional): coefficient that scale delta before it is applied\n            to the parameters (default: 1.0)\n        max_norm (float, optional): maximum norm of the individual gradient,\n            to which they will be clipped if exceeded (default: 0.01)\n        stddev (float, optional): standard deviation of the added noise\n            (default: 1.0)\n    \"\"\"\n\n    def __init__(self, params, lr=0.1, max_norm=0.01, stddev=2.0):\n        self.lr = lr\n        self.max_norm = max_norm\n        self.stddev = stddev\n        super().__init__(params, dict())\n\n    def step(self):\n        \"\"\"Performs a single optimization step.\n\n        The function expects the gradients to have been computed by BackPACK\n        and the parameters to have a ``batch_l2`` and ``grad_batch`` attribute.\n        \"\"\"\n        l2_norms_all_params_list = []\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                l2_norms_all_params_list.append(p.batch_l2)\n\n        l2_norms_all_params = torch.stack(l2_norms_all_params_list)\n        total_norms = torch.sqrt(torch.sum(l2_norms_all_params, dim=0))\n        scaling_factors = torch.clamp_max(total_norms / self.max_norm, 1.0)\n\n        for group in self.param_groups:\n            for p in group[\"params\"]:\n                clipped_grads = p.grad_batch * make_broadcastable(\n                    scaling_factors, p.grad_batch\n                )\n                clipped_grad = torch.sum(clipped_grads, dim=0)\n\n                noise_magnitude = self.stddev * self.max_norm\n                noise = torch.randn_like(clipped_grad) * noise_magnitude\n\n                perturbed_update = clipped_grad + noise\n\n                p.data.add_(-self.lr * perturbed_update)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Running and plotting\n--------------------\nWe can now run our optimizer on MNIST.\n\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "optimizer = DP_SGD(model.parameters(), lr=0.1, max_norm=0.01, stddev=2.0)\n\nlosses = []\naccuracies = []\nfor epoch in range(NUM_EPOCHS):\n    for batch_idx, (x, y) in enumerate(mnist_dataloader):\n        x, y = x.to(DEVICE), y.to(DEVICE)\n\n        model.zero_grad()\n\n        outputs = model(x)\n        loss = loss_function(outputs, y)\n\n        with backpack(BatchGrad(), BatchL2Grad()):\n            loss.backward()\n\n        optimizer.step()\n\n        # Logging\n        losses.append(loss.detach().item())\n        accuracies.append(accuracy(outputs, y))\n\n        if (batch_idx % PRINT_EVERY) == 0:\n            print(\n                \"Epoch %3.d/%d Iteration %3.d \" % (epoch, NUM_EPOCHS, batch_idx)\n                + \"Minibatch Loss %.3f  \" % losses[-1]\n                + \"Accuracy %.3f\" % accuracies[-1]\n            )\n\n        if MAX_ITER is not None and batch_idx > MAX_ITER:\n            break"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "fig = plt.figure()\naxes = [fig.add_subplot(1, 2, 1), fig.add_subplot(1, 2, 2)]\n\naxes[0].plot(losses)\naxes[0].set_title(\"Loss\")\naxes[0].set_xlabel(\"Iteration\")\n\naxes[1].plot(accuracies)\naxes[1].set_title(\"Accuracy\")\naxes[1].set_xlabel(\"Iteration\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}